#!/bin/bash

[ "$UID" -eq 0 ] || exec sudo bash "$0" "$@"

# Get the current path
MY_PATH="`dirname \"$0\"`"

# Script constants
PROJECT_NAME="spark"
PROJECT_WORK_DIR="$MY_PATH/work"
CONTAINER_HOME="/home/jovyan"

# Header
echo "Preparing to start Spark container..."

# Start the installation script if the work directory doesn't exist
if [ ! -d "$PROJECT_WORK_DIR" ]; then
    echo "The work directory isn't available, starting installation script..."
    ./install
fi

# Start the docker container
echo "Starting Spark container using Docker..."
sudo docker-compose -f "$MY_PATH/docker-compose.yml" -p "$PROJECT_NAME" up -d

# Copy installation script to the container, and run it
sudo docker cp "$MY_PATH/container/setup" "spark_spark_1:$CONTAINER_HOME/setup"
sudo docker cp "$MY_PATH/container/geturl" "spark_spark_1:$CONTAINER_HOME/geturl"
sudo docker exec spark_spark_1 "$CONTAINER_HOME/setup"

# It takes a while for notebook to start, wait for this
echo "Waiting 2 seconds for Jupyter notebook to start..."
sleep 2s

# Get the URL of the running notebook instance
NOTEBOOK_URL=$(sudo docker exec -i -t spark_spark_1 "$CONTAINER_HOME/geturl")

# Open Notebook in the default browser
echo "Opening Jupyter Notebook in your default browser..."
xdg-open "$NOTEBOOK_URL"

# Show the URL of the running notebook instance
echo
echo "Notebook is running at:"
echo "$NOTEBOOK_URL"
echo
echo "Use './stop' to stop the container."

