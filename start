#!/bin/bash

# Get the current path
MY_PATH="`dirname \"$0\"`"

# Script constants
PROJECT_NAME="spark"
PROJECT_WORK_DIR="$MY_PATH/work"
CONTAINER_HOME="/home/jovyan"

# Header
echo "Container start script."

# Start the installation script if the work directory doesn't exist
if [ ! -d "$PROJECT_WORK_DIR" ]; then
    echo "The work directory isn't available, starting installation script..."
    ./install
else
    echo "The work directory is available."
fi

# Start the docker container
echo "Starting Spark container using Docker..."
sudo docker-compose -f "$MY_PATH/docker-compose.yml" -p "$PROJECT_NAME" up -d

# Copy installation script to the container, and run it
ech "Running set up script on container..."
sudo docker cp "./container/setup" "spark_spark_1:$CONTAINER_HOME/setup"
sudo docker exec spark_spark_1 "$CONTAINER_HOME/setup"

# It takes a while for notebook to start, wait for this
echo "Waiting 2 seconds for Jupyter notebook to start..."
sleep 2s

# List the running jupyter notebook instances and get the notebook URL
INSTANCE_LIST=$(sudo docker exec -i -t spark_spark_1 jupyter notebook list)
NOTEBOOK_URL=$(echo "$INSTANCE_LIST" | tail -n 1 | sed 's/\ *//;s/\ ::.*//')

# Open Notebook in the default browser
echo "Opening Jupyter Notebook in your default browser..."
xdg-open $NOTEBOOK_URL

# Show the URL of the running notebook instance
echo
echo "Notebook is running at:"
echo "$NOTEBOOK_URL"
echo
echo "Use './stop' to stop the container."

